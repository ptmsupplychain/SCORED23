[{"model": "distilgpt2", "monthly_downloads": 16700000}, {"model": "bert-base-uncased", "monthly_downloads": 16400000}, {"model": "gpt2", "monthly_downloads": 13100000}, {"model": "distilbert-base-uncased-fintuned-sst-2-english", "monthly_downloads": 11000000}, {"model": "roberta-base", "monthly_downloads": 8690000}, {"model": "distilbert-base-uncased", "monthly_downloads": 7830000}, {"model": "SEBIS/code_trans_t5_small_program_synthese_transfer_learning_finetune", "monthly_downloads": 5570000}, {"model": "bert-base-cased", "monthly_downloads": 5490000}, {"model": "hfl/chinese-roberta-wwm-ext", "monthly_downloads": 5470000}, {"model": "openai/clip-vit-base-patch32", "monthly_downloads": 5260000}, {"model": "cl-tohoku/bert-base-japanese", "monthly_downloads": 4820000}, {"model": "unc-nlp/lxmert-base-uncased", "monthly_downloads": 4230000}, {"model": "Helsinki-NLP/opus-mt-zh-en", "monthly_downloads": 3710000}, {"model": "xlm-roberta-base", "monthly_downloads": 3680000}, {"model": "bert-base-chinese", "monthly_downloads": 2830000}, {"model": "roberta-large", "monthly_downloads": 2710000}, {"model": "bert-base-multilingual-cased", "monthly_downloads": 2470000}, {"model": "sentence-transformers/bert-base-nli-mean-tokens", "monthly_downloads": 2460000}, {"model": "sentence-transformers/all-MiniLM-L6-v2", "monthly_downloads": 2080000}, {"model": "sentence-transformers/paraphrase-MiniLM-L6-v2", "monthly_downloads": 2040000}]